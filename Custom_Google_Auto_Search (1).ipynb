{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/aideenf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from googleapiclient.discovery import build\n",
    "import xlrd\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.probability import ConditionalFreqDist \n",
    "from nltk.probability import FreqDist \n",
    "\n",
    " \n",
    "set(stopwords.words('spanish'))\n",
    "nltk.download('wordnet')\n",
    "\n",
    "#$ pip install ipyupload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from ipyupload import FileUpload\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set the Google custom search API credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_api_key = \"AIzaSyBbQ0YzDhZ6rj9_NISkM63x0MZAh1JW4cU\"\n",
    "my_cse_id = \"013450158706841933252:c2tfv5iyxis\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the spreadsheet containing the goal keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the file containing the Goals\n",
    "goals = FileUpload(accept='.csv',\n",
    "                multiple=False,\n",
    "                disabled=False,\n",
    "                style_button='color: darkblue; background-color: lightsalmon; width: 180px;',\n",
    "                compress_level=9\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0b067ac02743d7be59da5da0124b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(accept='.csv', compress_level=9, style_button='color: darkblue; background-color: lightsalmon; widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    print (\"File uploaded: \", goals.li_metadata[0]['name'])\n",
    "except:\n",
    "        print (\"Select a file to upload\")\n",
    "        \n",
    "goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfGoals = pd.read_excel(\n",
    "    '/Users/aideenf/Documents/GitHub/Juan/Automatic_Search/goals_191507.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select the spreadsheet containing the search terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the file containing the Goals\n",
    "searchTerms = FileUpload(accept='.csv',\n",
    "                multiple=False,\n",
    "                disabled=False,\n",
    "                style_button='color: darkblue; background-color: lightsalmon; width: 180px;',\n",
    "                compress_level=9\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a file to upload\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be3b0227b3f74fe19500082d30d4e397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(accept='.csv', compress_level=9, style_button='color: darkblue; background-color: lightsalmon; widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    print (\"File uploaded: \", searchTerms.li_metadata[0]['name'])\n",
    "except:\n",
    "        print (\"Select a file to upload\")\n",
    "        \n",
    "searchTerms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_excel (r'/Users/aideenf/Documents/GitHub/compas-analysis-master/compas-scores-two-years.csv', sheet_name='Type here the name of your Excel sheet')\n",
    "# if we do not need to specify sheet name\n",
    "df = pd.read_excel(\n",
    "    '/Users/aideenf/Documents/GitHub/Juan/Automatic_Search/zara_data_2016_17_modified.xlsx', 'zara_es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     trajes zara hombre precios\n",
       "1     trajes hombre zara precios\n",
       "2            trajes zara precios\n",
       "3                   zara precios\n",
       "4              ropa zara precios\n",
       "5           precios de ropa zara\n",
       "6                precios de zara\n",
       "7        precios de ropa en zara\n",
       "8             zara chile precios\n",
       "9       compra online zara mujer\n",
       "10                  zara on line\n",
       "11                    zara hogar\n",
       "12                 zara en linea\n",
       "13                       zara es\n",
       "14           zara tallas grandes\n",
       "Name: Keyword, dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The search phrases from the \"Keyword\" column of the original xlsx. Maybe these can be read directly \n",
    "#from the other google API. \n",
    "df[\"Keyword\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     advice\n",
       "1     advice\n",
       "2     advice\n",
       "3     advice\n",
       "4     advice\n",
       "5     advice\n",
       "6     advice\n",
       "7     advice\n",
       "8     advice\n",
       "9     advice\n",
       "10     brand\n",
       "11     brand\n",
       "12     brand\n",
       "13     brand\n",
       "14     brand\n",
       "Name: refine_search_goal, dtype: object"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"refine_search_goal\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Goal</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>website</td>\n",
       "      <td>brand</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>marca</td>\n",
       "      <td>brand</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>productos</td>\n",
       "      <td>brand</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shop</td>\n",
       "      <td>brand</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ww</td>\n",
       "      <td>brand</td>\n",
       "      <td>1</td>\n",
       "      <td>es</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Keyword   Goal  Weight Region\n",
       "0    website  brand       1     es\n",
       "1      marca  brand       1     es\n",
       "2  productos  brand       1     es\n",
       "3       shop  brand       1     es\n",
       "4         ww  brand       1     es"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The first 5 lines from the goal/keyword mapping xls. \n",
    "dfGoals.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of search terms to be processed:  682\n"
     ]
    }
   ],
   "source": [
    "#Get a list of unique Search trtms (keywords), we can probably read these directly from Googpe Ad API\n",
    "search_terms_arr  = df['Keyword'].unique()\n",
    "print (\"The number of search terms to be processed: \", len(search_terms_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# http://www.nltk.org/book/ch03.html\n",
    "https://machinelearningmastery.com/clean-text-machine-learning-python/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################################\n",
    "# using NLTK library take Google Response, tokenize, lower case, remove stop words, lemmatize,\n",
    "# stem etc and return an NLTK FreqDist object.\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def processResponse(example_sent):\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Raw Google Response: \", example_sent)\n",
    "    print(\"\")\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    # Combine the spanish and english stop words as some of the responses are mixed language\n",
    "    # stopwords considered as noise in the text. Text may contain stop words such as\n",
    "    # is, am, are, this, a, an, the, etc. In NLTK for removing stopwords, you need to create\n",
    "    # a list of stopwords and filter out your list of tokens from these words.There are default\n",
    "    # lists for some languages, here we use the default spanish and english stoplist(blacklist)\n",
    "    spanish_stop_words = set(stopwords.words('spanish'))\n",
    "    english_stop_words = set(stopwords.words('english'))\n",
    "    stop_words = spanish_stop_words.union(english_stop_words)\n",
    "\n",
    "    # Tokenization is the first step in text analytics. The process of breaking down\n",
    "    # a text paragraph into smaller chunks such as words or sentence is called Tokenization.\n",
    "    # Token is a single entity that is building blocks for sentence or paragraph. Here we are breaking\n",
    "    # a sentence into individual words\n",
    "    word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "    # convert to lower case\n",
    "    word_tokens = [w.lower() for w in word_tokens]\n",
    "    print(\"--Tokenized and converted to lower case\")\n",
    "\n",
    "    # Only keep alpha characters, no special chars or words containing numerics\n",
    "    # should change this to also keep numerics....\n",
    "    words = [word for word in word_tokens if word.isalpha()]\n",
    "    print(\"--Words parsed to only retain alpha chars\")\n",
    "    numbers = [word for word in word_tokens if word.isnumeric()]\n",
    "    print(\"--Words parsed to only retain numeric chars\", numbers)\n",
    "    words = words + numbers\n",
    "\n",
    "    # Remove the stop words (we are removing the english and spanish stop words)\n",
    "    filtered_sentence = [w for w in words if not w in stop_words]\n",
    "    filtered_sentence = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(ps.stem(wnl.lemmatize(w)))\n",
    "    print(\"--Stopwords removed and remaining words Lemmatized and stemmed\")\n",
    "    # print(filtered_sentence)\n",
    "\n",
    "    fDist = FreqDist(filtered_sentence)\n",
    "    return fDist, filtered_sentence\n",
    "\n",
    "\n",
    "#######################################################################\n",
    "# using NLTK library take string, tokenize, lower case, remove stop words, lemmatize,\n",
    "# stem etc and return the processed string.\n",
    "########################################################################\n",
    "def processString(example_sent):\n",
    "\n",
    "    ps = PorterStemmer()\n",
    "    wnl = WordNetLemmatizer()\n",
    "\n",
    "    # Combine the spanish and english stop words as some of the responses are mixed language\n",
    "    # stopwords considered as noise in the text. Text may contain stop words such as\n",
    "    # is, am, are, this, a, an, the, etc. In NLTK for removing stopwords, you need to create\n",
    "    # a list of stopwords and filter out your list of tokens from these words.There are default\n",
    "    # lists for some languages, here we use the default spanish and english stoplist(blacklist)\n",
    "    spanish_stop_words = set(stopwords.words('spanish'))\n",
    "    english_stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    stop_words = [\"a\"]\n",
    "  \n",
    "    stop_words = spanish_stop_words.union(english_stop_words)\n",
    "\n",
    "    # Tokenization is the first step in text analytics. The process of breaking down\n",
    "    # a text paragraph into smaller chunks such as words or sentence is called Tokenization.\n",
    "    # Token is a single entity that is building blocks for sentence or paragraph. Here we are breaking\n",
    "    # a sentence into individual words\n",
    "    word_tokens = word_tokenize(example_sent)\n",
    "\n",
    "    # convert to lower case\n",
    "    word_tokens = [w.lower() for w in word_tokens]\n",
    "    print(\"--Tokenized and converted to lower case\")\n",
    "\n",
    "    # Only keep alpha characters, no special chars or words containing numerics\n",
    "    words = [word for word in word_tokens if word.isalpha()]\n",
    "    # --Words parsed to only retain alpha chars\"\n",
    "    numbers = [word for word in word_tokens if word.isnumeric()]\n",
    "    # --Words parsed to only retain numeric chars \", numbers)\n",
    "    words = numbers + words\n",
    "    print(\"--Words parsed: \", words) \n",
    "    \n",
    "    # Remove the stop words (we are removing the english and spanish stop words)\n",
    "    filtered_string = [w for w in words if not w in stop_words]\n",
    "    filtered_string = []\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_string.append(ps.stem(wnl.lemmatize(w)))\n",
    "    print(\"--Stopwords removed and remaining words Lemmatized and stemmed\")\n",
    "\n",
    "    fDist = FreqDist(filtered_string)\n",
    "    return fDist, filtered_string\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#   makes the actual call to the custom Search engine api\n",
    "########################################################################\n",
    "def google_search(search_term, api_key, cse_id, **kwargs):\n",
    "    service = build(\"customsearch\", \"v1\", developerKey=api_key, cache_discovery=False)\n",
    "    res = service.cse().list(q=search_term, cx=cse_id, **kwargs).execute()\n",
    "    return res['items']\n",
    "\n",
    "\n",
    "########################################################################\n",
    "#   Takes a search phrase as input and returns the google api response.\n",
    "#########################################################################\n",
    "def search_phrase(phrase):\n",
    "    # num = integer, Number of search results to return\n",
    "    # CHANGE num to 10 later once testing is complete\n",
    "    print (\"In search_phrase\")\n",
    "    results = google_search(phrase, my_api_key, my_cse_id, num=10)\n",
    "    return results\n",
    "\n",
    "########################################################################\n",
    "#   Takes the result from the google Search and strips the necessary information\n",
    "#   Returns the combined text from the snippet, title and url of the responses\n",
    "########################################################################\n",
    "\n",
    "\n",
    "def get_word_list(results):\n",
    "    # Take the relevant fields ie formattedUrl/breadcrumb/snippet/title\n",
    "    # need to investigate further as there are not always breadcrumb\n",
    "    # 'https://www.milanuncios.com/moda-<b>hombre</b>/<b>trajes</b>-<b>zara</b>.htm',\n",
    "    snippet = \"\"\n",
    "    title = \"\"\n",
    "    htmlFormattedUrl = \"\"\n",
    "    urlsInResponseArray = []\n",
    "    for result in results:\n",
    "        formattedUrl = result[\"formattedUrl\"]\n",
    "        snippet = snippet + \" \" + result[\"snippet\"] + \" \"\n",
    "        title = title + \" \" + result[\"title\"] + \" \"\n",
    "        htmlFormattedUrl = htmlFormattedUrl + \\\n",
    "            \" \" + result[\"htmlFormattedUrl\"] + \" \"\n",
    "        urlsInResponseArray.append(formattedUrl)\n",
    "    urlWords = re.findall(r'\\b[>]\\w+', htmlFormattedUrl)\n",
    "    urlWords = ''.join(urlWords)\n",
    "    allText = title + \" \" + snippet + \" \" + urlWords\n",
    "\n",
    "    return allText, urlsInResponseArray\n",
    "\n",
    "\n",
    "############################\n",
    "# Method used to combine the two scores per goal(stored in dictionary) and add a weight(extraWeight) to\n",
    "# the scores from the Search phrase score\n",
    "###########################\n",
    "def mergsum(googleRespScores, searchPhraseScores, extraWeight):\n",
    "    res = {}\n",
    "    combined = {}\n",
    "    for k in searchPhraseScores:\n",
    "        if k in googleRespScores:\n",
    "            searchPhraseScores[k] = (searchPhraseScores[k]*extraWeight) + googleRespScores[k]\n",
    "    #res = {**googleRespScores, **searchPhraseScores}\n",
    "    #return res\n",
    "    print (searchPhraseScores)\n",
    "    return searchPhraseScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user intent/Goal obtain a list of keywords and save in dictionary\n",
    "goalArr = dfGoals['Goal'].unique()\n",
    "goalNameKeywordDict = {\n",
    "}\n",
    "\n",
    "ps = PorterStemmer()\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "# For each goal/user intention in the goalArr\n",
    "for goal in goalArr:\n",
    "    KeywordWeightDict = {\n",
    "        }\n",
    "     #print(\" \")\n",
    "     #print(\"GOAL = \", goal)\n",
    "    # retrieve a list of Keywords for the goal from the dataFrame.\n",
    "    goalKeywords = dfGoals[dfGoals['Goal'].str.contains(\n",
    "        goal)].Keyword.unique().tolist()\n",
    "    \n",
    "    # For each keyword for the goal, obtain the matching weight. \n",
    "    for word in goalKeywords:\n",
    "        resp = dfGoals[(dfGoals['Goal'] == goal) & (dfGoals['Keyword'] == word)][\"Weight\"]\n",
    "        #store the weight in a dictionary with the stemmed/lemmatized keyword\n",
    "        KeywordWeightDict[(ps.stem(wnl.lemmatize(str(word).lower())))] = int(resp[:1])\n",
    "    # addding dictionary to a dictionary.\n",
    "    goalNameKeywordDict[goal] = KeywordWeightDict\n",
    " #print (\"FINAL RESULT is Dictionary of GOALS\")\n",
    " #print (goalNameKeywordDict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#eventually do for all search phrases\n",
    "#START FOR\n",
    "##for i in search_terms_arr:\n",
    "##searchString = i #for all search phrases use this line\n",
    "\n",
    "def main_method(searchString):\n",
    "    #Do a google search for the search phrase in the list of search phrases and save the google API response in 'results'\n",
    "    results = search_phrase(searchString)\n",
    "\n",
    "\n",
    "    #Takes the result from the google Search and strips the necessary information to return\n",
    "    #the combined text from the snippet, title and url of the results and save in 'responseswordList' AND \n",
    "    #save the list of URL's returned from the search in URLsReturnedFromGoogle\n",
    "    responseWordList, URLsReturnedFromGoogle = get_word_list(results)\n",
    "\n",
    "\n",
    "    # process the word list from the google response(set all to lowercase, remove stop words, stem, lemmatizw etc) \n",
    "    # and returm to \"wordFreqDist\" an nltk.probability FreqDist object containing the frequency distribution\n",
    "    # of all the words in the response (a list of words and how often each occurs)\n",
    "    wordFreqDistGoogleResp, processedGoogleResp = processResponse(responseWordList)\n",
    "\n",
    "    #print the top 10 most common words in the google search response.\n",
    "    print(\"\")\n",
    "    print(\"Top 10 most common words in Google search response:\")\n",
    "    print (wordFreqDistGoogleResp.most_common(10))\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"URL's returned in Google search response:\")\n",
    "    for url in URLsReturnedFromGoogle:\n",
    "        print(url)\n",
    "    \n",
    "    #process the search string itself and save the tokenized,stemmed,lematized etc in 'search_tokens'\n",
    "    print(\"\")\n",
    "    print(\"Processing Search phrase:\" , searchString)\n",
    "    wordFreqDistSearchPhrase, search_tokens = processString(searchString) \n",
    "    print(\"Search phrase processed via NLTK lib:\" , search_tokens)\n",
    "    print(\"\")\n",
    "    wordFreqDistGoogleResp.plot(10, cumulative=False)\n",
    "    print (len(processedGoogleResp))\n",
    "    \n",
    "    return wordFreqDistSearchPhrase,wordFreqDistGoogleResp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def getScores(wordFreqDistSearchPhrase,wordFreqDistGoogleResp,goalNameKeywordDict):\n",
    "    # Now we have \n",
    "    # - the tokenized search phrase\n",
    "    # - the tokenized search response\n",
    "    # - \"wordFreqDist\" as nltk.probability FreqDist of words in the response.\n",
    "    # - the tokenized keywords for each goal/intent in a dictionary goalNameKeywordDict\n",
    "\n",
    "    #obtain the frequency distribution of the goal keywords in the SEARCH PHRASE\n",
    "\n",
    "    goalSearchAvgDict = {}\n",
    "    goalSearchTotalDict = {}\n",
    "    goalRespAvgDict = {}\n",
    "    goalRespTotalDict = {}\n",
    "\n",
    "\n",
    "    print (\"///////////SEARCH PHRASE MATCHED TO GOAL KEYWORDS///////////////////\")\n",
    "    print (\"\")\n",
    "    for goal in goalNameKeywordDict:\n",
    "   \n",
    "        print (\"/////////////////////////////////\")\n",
    "        print (\"GOAL:\", goal)\n",
    "        print (\"/////////////////////////////////\")\n",
    "        total = 0\n",
    "        for word in goalNameKeywordDict.get(goal):\n",
    "            keyword_weight = goalNameKeywordDict.get(goal).get(word)\n",
    "            #The word frequency distribution of each keyword for this goal in the search phrase\n",
    "            #i.e probability of the keyword being in the search phrase  \n",
    "            print (word,keyword_weight, wordFreqDistSearchPhrase.freq(word))\n",
    "            total = total + (wordFreqDistSearchPhrase.freq(word)/keyword_weight)\n",
    "        average = total/len(goalNameKeywordDict.get(goal))  \n",
    "        print(\"Average distribution of goal [\", goal, \"] keywords in the search phrase \", average)\n",
    "        print(\"Total combined distribution of goal [\", goal, \"] keywords in the search phrase \", total)\n",
    "        print(\"\")\n",
    "        goalSearchAvgDict [goal] = average\n",
    "        goalSearchTotalDict [goal] = total\n",
    "    print (\"\")\n",
    "    print (\"**The most likely goal according to search phrase using average:\", max(goalSearchAvgDict, key=goalSearchAvgDict.get))\n",
    "    print (\"**The most likely goal according to search phrase using total:\", max(goalSearchTotalDict, key=goalSearchTotalDict.get))\n",
    "    print (\"\")\n",
    "\n",
    "\n",
    "    #obtain the frequency distribution of the \"goal keywords\" in the google response. \n",
    "    print (\"///////////GOOGLE SEARCH RESPONSE MATCHED TO GOAL KEYWORDS///////////////////\")\n",
    "    print (\"\")\n",
    "    for goal in goalNameKeywordDict:\n",
    "        print (\"/////////////////////////////////\")\n",
    "        print (\"GOAL:\", goal)\n",
    "        print (\"/////////////////////////////////\")\n",
    "        total = 0\n",
    "        for word in goalNameKeywordDict.get(goal):\n",
    "            #The word frequency distribution of each keyword for this goal in the google response\n",
    "            #i.e probability of the keyword being in the Google Response.\n",
    "            keyword_weight = goalNameKeywordDict.get(goal).get(word)\n",
    "            total = total + (wordFreqDistGoogleResp.freq(word) / keyword_weight)\n",
    "            print (word, keyword_weight, wordFreqDistGoogleResp.freq(word))\n",
    "        average = total/len(goalNameKeywordDict.get(goal))  \n",
    "        print(\"Average distribution of goal [\", goal, \"] keywords in the response \", average)\n",
    "        print(\"Total combined distribution of goal [\", goal, \"] keywords in the response \", total)\n",
    "        print(\"\")\n",
    "        goalRespAvgDict [goal] = average\n",
    "        goalRespTotalDict [goal] = total\n",
    "    print (\"\")\n",
    "    print (\"**The most likely goal according to search response using average:\", max(goalRespAvgDict, key=goalRespAvgDict.get))\n",
    "    print (\"**The most likely goal according to search response using total:\", max(goalRespTotalDict, key=goalRespTotalDict.get))\n",
    "\n",
    "    \n",
    "    #get a combined score for search phrase and googles response, Yeah Baby!\n",
    "    #Double check these calcs manually to make sure the implementatino is correct, here we apply a weight of 1.5 to the goal\n",
    "    #scores generated by the search phrase, this is to give the search phrase more impact in terms of identifying the goal\n",
    "    #than the response has, set to 1 for no impact.\n",
    "\n",
    "    extraWeightForSearchPhrase = 1.5\n",
    "    #print  (goalRespAvgDict)\n",
    "    #print  (goalSearchAvgDict)\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"NOW COMBINE THE SCORE FROM SEARCH PHRASE AND RESPONSE\")\n",
    "    print(\"\")\n",
    "    print(\"USING AVERAGE SCORE PER KEYWORD\")\n",
    "    c = mergsum(goalRespAvgDict, goalSearchAvgDict, extraWeightForSearchPhrase )\n",
    "\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"USING SUM/TOTAL OF SCORES PER KEYWORD\")\n",
    "    d = mergsum(goalRespTotalDict, goalSearchTotalDict, extraWeightForSearchPhrase )\n",
    "\n",
    "\n",
    "    print (\"\")\n",
    "    print (\"Using a Score that is combination of search phrase goal score and google response goal score \")\n",
    "    print (\"\")\n",
    "    print (\"**The most likely goal using the average approach:\", max(c, key=c.get))\n",
    "    print (\"**The most likely goal using the total approach:\", max(d, key=d.get))\n",
    "#END FOR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "textBox = widgets.Text()\n",
    "btn = widgets.Button(description='Search')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d276c52a39264d479e566799819607fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660a519214374679a0ea3c8de6ab4edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Search', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GOOGLE SEARCH FOR:  trajes hombre zara precios\n",
      "In search_phrase\n",
      "\n",
      "Raw Google Response:   Trajes para hombre | Nueva Colección Online | ZARA España  Trajes de hombre Zara online. ¡Compara 395 productos y compra!  Trajes-BÁSICOS-HOMBRE | ZARA España  Trajes Zara para hombre Primavera Verano 2019 - Modaellos.com  Colección Hombre | Nueva Colección Online | ZARA España  ZARA - SPECIAL PRICES - TRAJE BASICO NEGRO. 90€ | Formal ...  Americanas y trajes para hombre - Últimas novedades | H&M ES  Traje Zara Hombre - Trajes de Hombre, Usado en Mercado Libre ...  Zara no ha inventado el traje antiarrugas... pero lo ha puesto a ...  MIL ANUNCIOS.COM - Comprar y vender moda hombre zara de ...   ENVÍO GRATUITO. No todos los trajes son iguales. Elige tu estilo y tu fit para el \n",
      "trabajo o para ocasiones especiales.  Zara Hombre Trajes completos - Blazer traje cinzato comfort. Zara. 59,95 €. Zara \n",
      "Blazer traje cinzato comfort. Zara Hombre Pantalones de traje - Pantalón traje ...  TRAJE ESENCIAL OJO DE PERDIZ · TRAJE CONJUNTO OJO DE PERDIZ. \n",
      "TRAJE CONJUNTO ESTRUCTURA · TRAJE CONJUNTO ESTRUCTURA.  12 Mar 2019 ... Si deseas vestir bien esta temporada de Primavera Verano, no te pierdas los \n",
      "Trajes Zara para hombre Primavera Verano.  ENVÍO GRATUITO. Descubre lo último en moda masculina. Nuevas prendas de \n",
      "la colección ZARA MAN cada semana.  Descubre ideas sobre Zara Hombre Traje. Discover the new .... Suit Trajes De \n",
      "Verano, Trajes De Hombre, Traje De Novio, Vestuarios, Moda. us.tiendas.com ...  Elegantes americanas y chalecos para hombre en distintos estilos, para el \n",
      "trabajo o la ... Americanas y trajes a medida para un look clásico y elegante.  Encontrá Traje Zara Hombre - Trajes de Hombre, Usado en Mercado Libre \n",
      "Argentina. Descubrí la mejor forma ... Costo de envío: Gratis (4). Tipo de entrega: \n",
      "Con ... Publicidad. Traje Slim Fit Negro Zara Man Talle S Para Adolescente. $ \n",
      "3.800 ...  14 Mar 2018 ... 14/03/2018. zara hombre traje antiarrugas viajes. Zara. Hace unos días ... que \n",
      "estaba en el mercado y la ha mejorado... sobre todo de precio.  Compra o vende moda hombre zara al mejor precio. Descubre en ... Trajes en. \n",
      "traje gris marengo de rayas, marca Zara, talla 54. atiendo email y whatsapp. 95€.  >zara>hombre>traje>hombre>trajes>zara>zara>hombre>traje>trajes>zara>hombre>zara>hombre>hombre>trajes>trajes>hombre>traje>zara>hombre>hombre>zara>traje>hombre>hombre>zara\n",
      "\n",
      "--Tokenized and converted to lower case\n",
      "--Words parsed to only retain alpha chars\n",
      "--Words parsed to only retain numeric chars ['395', '2019', '12', '2019', '4', '14', '2018']\n",
      "--Stopwords removed and remaining words Lemmatized and stemmed\n",
      "\n",
      "Top 10 most common words in Google search response:\n",
      "[('traje', 38), ('zara', 30), ('hombr', 29), ('colección', 4), ('verano', 4), ('moda', 4), ('nueva', 3), ('onlin', 3), ('españa', 3), ('primavera', 3)]\n",
      "\n",
      "URL's returned in Google search response:\n",
      "https://www.zara.com/es/es/hombre-traje-l808.html\n",
      "https://www.fashiola.es/hombre/ropa/trajes-y-formal/?mrk=zara\n",
      "https://www.zara.com/es/es/hombre-traje-basicos-l811.html\n",
      "https://modaellos.com/trajes-zara-hombre/\n",
      "https://www.zara.com/es/es/hombre-l534.html\n",
      "https://www.pinterest.com/pin/502221795931049313/\n",
      "https://www2.hm.com/es_es/hombre/.../americanas-y-trajes.html\n",
      "https://ropa.mercadolibre.com.ar/trajes/hombre/.../traje-zara-hombre\n",
      "https://www.esquire.com/...hombre/.../zara-traje-hombre-antiarrugas-viajes/\n",
      "https://www.milanuncios.com/moda-hombre/zara.htm\n",
      "\n",
      "Processing Search phrase: trajes hombre zara precios\n",
      "--Tokenized and converted to lower case\n",
      "--Words parsed:  ['trajes', 'hombre', 'zara', 'precios']\n",
      "--Stopwords removed and remaining words Lemmatized and stemmed\n",
      "Search phrase processed via NLTK lib: ['traje', 'hombr', 'zara', 'precio']\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "251\n",
      "///////////SEARCH PHRASE MATCHED TO GOAL KEYWORDS///////////////////\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: brand\n",
      "/////////////////////////////////\n",
      "websit 1 0.0\n",
      "marca 1 0.0\n",
      "producto 1 0.0\n",
      "shop 1 0.0\n",
      "ww 1 0.0\n",
      "www 1 0.0\n",
      "zara 1 0.25\n",
      " e 1 0.0\n",
      " en 1 0.0\n",
      "historia 3 0.0\n",
      " line 2 0.0\n",
      "web 1 0.0\n",
      "onlin 3 0.0\n",
      "ropa 2 0.0\n",
      "Average distribution of goal [ brand ] keywords in the search phrase  0.017857142857142856\n",
      "Total combined distribution of goal [ brand ] keywords in the search phrase  0.25\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: transactional\n",
      "/////////////////////////////////\n",
      "venta 1 0.0\n",
      "ropa 1 0.0\n",
      "onlin 1 0.0\n",
      "comprar 1 0.0\n",
      "compra 1 0.0\n",
      "internet 1 0.0\n",
      "shop 1 0.0\n",
      "tienda 1 0.0\n",
      "line 1 0.0\n",
      "web 2 0.0\n",
      "websit 2 0.0\n",
      "cuenta 1 0.0\n",
      "devolucion 2 0.0\n",
      "envio 2 0.0\n",
      "tarjeta 1 0.0\n",
      "regalo 1 0.0\n",
      "zara 1 0.25\n",
      "ticket 1 0.0\n",
      "Average distribution of goal [ transactional ] keywords in the search phrase  0.013888888888888888\n",
      "Total combined distribution of goal [ transactional ] keywords in the search phrase  0.25\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: entertaiment\n",
      "/////////////////////////////////\n",
      "catalogo 1 0.0\n",
      "facebook 1 0.0\n",
      "instagram 1 0.0\n",
      "foto 1 0.0\n",
      "video 1 0.0\n",
      "colección 1 0.0\n",
      "noticia 1 0.0\n",
      "desfil 1 0.0\n",
      "novedad 1 0.0\n",
      "newslett 1 0.0\n",
      "youtub 1 0.0\n",
      "pinterest 1 0.0\n",
      "twitter 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ entertaiment ] keywords in the search phrase  0.005952380952380952\n",
      "Total combined distribution of goal [ entertaiment ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: obtain\n",
      "/////////////////////////////////\n",
      "inditex 1 0.0\n",
      "empleo 1 0.0\n",
      "fundador 1 0.0\n",
      "logo 1 0.0\n",
      "historia 1 0.0\n",
      "zara 3 0.25\n",
      "empresa  1 0.0\n",
      "oficina 1 0.0\n",
      "trabaja 1 0.0\n",
      "trabajar 1 0.0\n",
      "telefono 2 0.0\n",
      "privacidad 2 0.0\n",
      "Average distribution of goal [ obtain ] keywords in the search phrase  0.006944444444444444\n",
      "Total combined distribution of goal [ obtain ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: advise\n",
      "/////////////////////////////////\n",
      "atencion 1 0.0\n",
      "comprar 3 0.0\n",
      "devolucion 1 0.0\n",
      "grand 1 0.0\n",
      "talla 1 0.0\n",
      "como 1 0.0\n",
      "condicion 1 0.0\n",
      "client 1 0.0\n",
      "ayuda 1 0.0\n",
      "cambio 1 0.0\n",
      "pedido 1 0.0\n",
      "cancelar 1 0.0\n",
      "contacto 2 0.0\n",
      "cuenta 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ advise ] keywords in the search phrase  0.005555555555555555\n",
      "Total combined distribution of goal [ advise ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: deals\n",
      "/////////////////////////////////\n",
      "deal 1 0.0\n",
      "outlet 1 0.0\n",
      "friday 1 0.0\n",
      "black 1 0.0\n",
      "ofertas   1 0.0\n",
      "promocion 1 0.0\n",
      "rebaja 1 0.0\n",
      "descuento 1 0.0\n",
      "verano 2 0.0\n",
      "zara 1 0.25\n",
      "invierno 2 0.0\n",
      "saldo 1 0.0\n",
      "liquidacion 1 0.0\n",
      "Average distribution of goal [ deals ] keywords in the search phrase  0.019230769230769232\n",
      "Total combined distribution of goal [ deals ] keywords in the search phrase  0.25\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: gender\n",
      "/////////////////////////////////\n",
      "señora 2 0.0\n",
      "mujer  2 0.0\n",
      "hombr 2 0.25\n",
      "niños  2 0.0\n",
      "niña 2 0.0\n",
      "niño 2 0.0\n",
      "nina 2 0.0\n",
      "nino 2 0.0\n",
      "bebe 2 0.0\n",
      "woman 2 0.0\n",
      "man 2 0.0\n",
      "kid 2 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ gender ] keywords in the search phrase  0.016025641025641024\n",
      "Total combined distribution of goal [ gender ] keywords in the search phrase  0.20833333333333331\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: list\n",
      "/////////////////////////////////\n",
      "abrigo 1 0.0\n",
      "accesorio 1 0.0\n",
      "bañadores  1 0.0\n",
      "bermuda 1 0.0\n",
      "bikini 1 0.0\n",
      "blazer 1 0.0\n",
      "bluse 1 0.0\n",
      "bodi 1 0.0\n",
      "bolsos  1 0.0\n",
      "camisas  1 0.0\n",
      "camisetas  1 0.0\n",
      "cazadora 1 0.0\n",
      "chándal 1 0.0\n",
      "chaqueta 1 0.0\n",
      "essenti 1 0.0\n",
      "faldas  1 0.0\n",
      "jean 1 0.0\n",
      "leggings  1 0.0\n",
      "mochila 1 0.0\n",
      "mono 1 0.0\n",
      "pantalon 1 0.0\n",
      "peto 1 0.0\n",
      "pijama 1 0.0\n",
      "polo 1 0.0\n",
      "punto 1 0.0\n",
      "short 1 0.0\n",
      "srpl 1 0.0\n",
      "sudadera 1 0.0\n",
      "top 1 0.0\n",
      "traje 1 0.25\n",
      "underwear  1 0.0\n",
      "vestido 1 0.0\n",
      "zapato 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ list ] keywords in the search phrase  0.00980392156862745\n",
      "Total combined distribution of goal [ list ] keywords in the search phrase  0.3333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: locale\n",
      "/////////////////////////////////\n",
      "españa 1 0.0\n",
      "home 2 0.0\n",
      "tienda 2 0.0\n",
      "onlin 2 0.0\n",
      "centro 1 0.0\n",
      "telefono 1 0.0\n",
      "europa 1 0.0\n",
      "horario 1 0.0\n",
      "ciudad 1 0.0\n",
      "career 1 0.0\n",
      "empresa 1 0.0\n",
      "curriculum 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ locale ] keywords in the search phrase  0.00641025641025641\n",
      "Total combined distribution of goal [ locale ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: target\n",
      "/////////////////////////////////\n",
      "joven 1 0.0\n",
      "niño 1 0.0\n",
      "bebe 1 0.0\n",
      "dama 1 0.0\n",
      "premama 1 0.0\n",
      "mujer 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ target ] keywords in the search phrase  0.011904761904761904\n",
      "Total combined distribution of goal [ target ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: trends\n",
      "/////////////////////////////////\n",
      "2015 1 0.0\n",
      "2016 1 0.0\n",
      "2017 1 0.0\n",
      "2018 1 0.0\n",
      "2019 1 0.0\n",
      "colección 1 0.0\n",
      "moda 1 0.0\n",
      "temporada 1 0.0\n",
      "tendencia 1 0.0\n",
      "ultima 1 0.0\n",
      "nueva 1 0.0\n",
      "primavera  1 0.0\n",
      "verano 1 0.0\n",
      "otoño 1 0.0\n",
      "invierno 1 0.0\n",
      "zara 3 0.25\n",
      "Average distribution of goal [ trends ] keywords in the search phrase  0.005208333333333333\n",
      "Total combined distribution of goal [ trends ] keywords in the search phrase  0.08333333333333333\n",
      "\n",
      "\n",
      "**The most likely goal according to search phrase using average: deals\n",
      "**The most likely goal according to search phrase using total: list\n",
      "\n",
      "///////////GOOGLE SEARCH RESPONSE MATCHED TO GOAL KEYWORDS///////////////////\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: brand\n",
      "/////////////////////////////////\n",
      "websit 1 0.0\n",
      "marca 1 0.00398406374501992\n",
      "producto 1 0.00398406374501992\n",
      "shop 1 0.0\n",
      "ww 1 0.0\n",
      "www 1 0.0\n",
      "zara 1 0.11952191235059761\n",
      " e 1 0.0\n",
      " en 1 0.0\n",
      "historia 3 0.0\n",
      " line 2 0.0\n",
      "web 1 0.0\n",
      "onlin 3 0.01195219123505976\n",
      "ropa 2 0.0\n",
      "Average distribution of goal [ brand ] keywords in the response  0.009391007398975526\n",
      "Total combined distribution of goal [ brand ] keywords in the response  0.13147410358565736\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: transactional\n",
      "/////////////////////////////////\n",
      "venta 1 0.0\n",
      "ropa 1 0.0\n",
      "onlin 1 0.01195219123505976\n",
      "comprar 1 0.00398406374501992\n",
      "compra 1 0.00796812749003984\n",
      "internet 1 0.0\n",
      "shop 1 0.0\n",
      "tienda 1 0.0\n",
      "line 1 0.0\n",
      "web 2 0.0\n",
      "websit 2 0.0\n",
      "cuenta 1 0.0\n",
      "devolucion 2 0.0\n",
      "envio 2 0.0\n",
      "tarjeta 1 0.0\n",
      "regalo 1 0.0\n",
      "zara 1 0.11952191235059761\n",
      "ticket 1 0.0\n",
      "Average distribution of goal [ transactional ] keywords in the response  0.00796812749003984\n",
      "Total combined distribution of goal [ transactional ] keywords in the response  0.14342629482071714\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: entertaiment\n",
      "/////////////////////////////////\n",
      "catalogo 1 0.0\n",
      "facebook 1 0.0\n",
      "instagram 1 0.0\n",
      "foto 1 0.0\n",
      "video 1 0.0\n",
      "colección 1 0.01593625498007968\n",
      "noticia 1 0.0\n",
      "desfil 1 0.0\n",
      "novedad 1 0.00398406374501992\n",
      "newslett 1 0.0\n",
      "youtub 1 0.0\n",
      "pinterest 1 0.0\n",
      "twitter 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ entertaiment ] keywords in the response  0.0042686397268070575\n",
      "Total combined distribution of goal [ entertaiment ] keywords in the response  0.05976095617529881\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: obtain\n",
      "/////////////////////////////////\n",
      "inditex 1 0.0\n",
      "empleo 1 0.0\n",
      "fundador 1 0.0\n",
      "logo 1 0.0\n",
      "historia 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "empresa  1 0.0\n",
      "oficina 1 0.0\n",
      "trabaja 1 0.0\n",
      "trabajar 1 0.0\n",
      "telefono 2 0.0\n",
      "privacidad 2 0.0\n",
      "Average distribution of goal [ obtain ] keywords in the response  0.0033200531208499337\n",
      "Total combined distribution of goal [ obtain ] keywords in the response  0.0398406374501992\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: advise\n",
      "/////////////////////////////////\n",
      "atencion 1 0.0\n",
      "comprar 3 0.00398406374501992\n",
      "devolucion 1 0.0\n",
      "grand 1 0.0\n",
      "talla 1 0.00398406374501992\n",
      "como 1 0.0\n",
      "condicion 1 0.0\n",
      "client 1 0.0\n",
      "ayuda 1 0.0\n",
      "cambio 1 0.0\n",
      "pedido 1 0.0\n",
      "cancelar 1 0.0\n",
      "contacto 2 0.0\n",
      "cuenta 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ advise ] keywords in the response  0.0030101814962372733\n",
      "Total combined distribution of goal [ advise ] keywords in the response  0.0451527224435591\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: deals\n",
      "/////////////////////////////////\n",
      "deal 1 0.0\n",
      "outlet 1 0.0\n",
      "friday 1 0.0\n",
      "black 1 0.0\n",
      "ofertas   1 0.0\n",
      "promocion 1 0.0\n",
      "rebaja 1 0.0\n",
      "descuento 1 0.0\n",
      "verano 2 0.01593625498007968\n",
      "zara 1 0.11952191235059761\n",
      "invierno 2 0.0\n",
      "saldo 1 0.0\n",
      "liquidacion 1 0.0\n",
      "Average distribution of goal [ deals ] keywords in the response  0.009806926141587496\n",
      "Total combined distribution of goal [ deals ] keywords in the response  0.12749003984063745\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: gender\n",
      "/////////////////////////////////\n",
      "señora 2 0.0\n",
      "mujer  2 0.0\n",
      "hombr 2 0.11553784860557768\n",
      "niños  2 0.0\n",
      "niña 2 0.0\n",
      "niño 2 0.0\n",
      "nina 2 0.0\n",
      "nino 2 0.0\n",
      "bebe 2 0.0\n",
      "woman 2 0.0\n",
      "man 2 0.00796812749003984\n",
      "kid 2 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ gender ] keywords in the response  0.007814894269077536\n",
      "Total combined distribution of goal [ gender ] keywords in the response  0.10159362549800796\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: list\n",
      "/////////////////////////////////\n",
      "abrigo 1 0.0\n",
      "accesorio 1 0.0\n",
      "bañadores  1 0.0\n",
      "bermuda 1 0.0\n",
      "bikini 1 0.0\n",
      "blazer 1 0.00796812749003984\n",
      "bluse 1 0.0\n",
      "bodi 1 0.0\n",
      "bolsos  1 0.0\n",
      "camisas  1 0.0\n",
      "camisetas  1 0.0\n",
      "cazadora 1 0.0\n",
      "chándal 1 0.0\n",
      "chaqueta 1 0.0\n",
      "essenti 1 0.0\n",
      "faldas  1 0.0\n",
      "jean 1 0.0\n",
      "leggings  1 0.0\n",
      "mochila 1 0.0\n",
      "mono 1 0.0\n",
      "pantalon 1 0.00398406374501992\n",
      "peto 1 0.0\n",
      "pijama 1 0.0\n",
      "polo 1 0.0\n",
      "punto 1 0.0\n",
      "short 1 0.0\n",
      "srpl 1 0.0\n",
      "sudadera 1 0.0\n",
      "top 1 0.0\n",
      "traje 1 0.15139442231075698\n",
      "underwear  1 0.0\n",
      "vestido 1 0.0\n",
      "zapato 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ list ] keywords in the response  0.00597609561752988\n",
      "Total combined distribution of goal [ list ] keywords in the response  0.20318725099601592\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: locale\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/////////////////////////////////\n",
      "españa 1 0.01195219123505976\n",
      "home 2 0.0\n",
      "tienda 2 0.0\n",
      "onlin 2 0.01195219123505976\n",
      "centro 1 0.0\n",
      "telefono 1 0.0\n",
      "europa 1 0.0\n",
      "horario 1 0.0\n",
      "ciudad 1 0.0\n",
      "career 1 0.0\n",
      "empresa 1 0.0\n",
      "curriculum 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ locale ] keywords in the response  0.004443763407906834\n",
      "Total combined distribution of goal [ locale ] keywords in the response  0.05776892430278884\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: target\n",
      "/////////////////////////////////\n",
      "joven 1 0.0\n",
      "niño 1 0.0\n",
      "bebe 1 0.0\n",
      "dama 1 0.0\n",
      "premama 1 0.0\n",
      "mujer 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ target ] keywords in the response  0.005691519635742743\n",
      "Total combined distribution of goal [ target ] keywords in the response  0.0398406374501992\n",
      "\n",
      "/////////////////////////////////\n",
      "GOAL: trends\n",
      "/////////////////////////////////\n",
      "2015 1 0.0\n",
      "2016 1 0.0\n",
      "2017 1 0.0\n",
      "2018 1 0.00398406374501992\n",
      "2019 1 0.00796812749003984\n",
      "colección 1 0.01593625498007968\n",
      "moda 1 0.01593625498007968\n",
      "temporada 1 0.00398406374501992\n",
      "tendencia 1 0.0\n",
      "ultima 1 0.0\n",
      "nueva 1 0.01195219123505976\n",
      "primavera  1 0.0\n",
      "verano 1 0.01593625498007968\n",
      "otoño 1 0.0\n",
      "invierno 1 0.0\n",
      "zara 3 0.11952191235059761\n",
      "Average distribution of goal [ trends ] keywords in the response  0.007221115537848606\n",
      "Total combined distribution of goal [ trends ] keywords in the response  0.1155378486055777\n",
      "\n",
      "\n",
      "**The most likely goal according to search response using average: deals\n",
      "**The most likely goal according to search response using total: list\n",
      "\n",
      "\n",
      "\n",
      "NOW COMBINE THE SCORE FROM SEARCH PHRASE AND RESPONSE\n",
      "\n",
      "USING AVERAGE SCORE PER KEYWORD\n",
      "{'brand': 0.036176721684689814, 'transactional': 0.028801460823373173, 'entertaiment': 0.013197211155378485, 'obtain': 0.0137367197875166, 'advise': 0.011343514829570606, 'deals': 0.03865307998774134, 'gender': 0.03185335580753907, 'list': 0.020681977970471055, 'locale': 0.014059148023291449, 'target': 0.0235486624928856, 'trends': 0.015033615537848606}\n",
      "\n",
      "USING SUM/TOTAL OF SCORES PER KEYWORD\n",
      "{'brand': 0.5064741035856574, 'transactional': 0.5184262948207171, 'entertaiment': 0.1847609561752988, 'obtain': 0.1648406374501992, 'advise': 0.1701527224435591, 'deals': 0.5024900398406374, 'gender': 0.414093625498008, 'list': 0.703187250996016, 'locale': 0.18276892430278885, 'target': 0.1648406374501992, 'trends': 0.2405378486055777}\n",
      "\n",
      "Using a Score that is combination of search phrase goal score and google response goal score \n",
      "\n",
      "**The most likely goal using the average approach: deals\n",
      "**The most likely goal using the total approach: list\n"
     ]
    }
   ],
   "source": [
    "display(textBox, btn )\n",
    "\n",
    "def btn_eventhandler(obj):\n",
    "    searchString = search_terms_arr[0]\n",
    "    searchString = textBox.value\n",
    "    print (\"GOOGLE SEARCH FOR: \", searchString)\n",
    "    wordFreqDistSearchPhrase,wordFreqDistGoogleResp = main_method(searchString)\n",
    "    getScores(wordFreqDistSearchPhrase,wordFreqDistGoogleResp,goalNameKeywordDict)\n",
    "    \n",
    "\n",
    "btn.on_click(btn_eventhandler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IGNORE TEXT BELOW."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The AdWords \"Keyword\" column\n",
    "\n",
    "The \"Keyword\" column tells you which one of your keywords matched someone’s search term and triggered your ad. This information can help you see your keywords “in action” by showing you how they are matching to actual searches. \n",
    "\n",
    "You can use the data in the \"Keyword\" column to improve your keyword list. For example, let’s say you sell tulips. When you look at your search terms report, you see that your broad match keyword flowers triggers your ad to show when people search for red roses and purple orchids -- flowers you don’t sell. So, you decide to refine your keyword list to focus on terms and phrases more specific to the products you do offer: tulips.\n",
    "\n",
    "Note for AdWord settings ... The \"Keyword\" column does not show by default. In the previous AdWords experience, turn on the “Keyword” column by clicking the Columns drop down menu and choosing “Modify columns.” In the \"Select metrics\" section, click Attributes. Then, click the Add link next to \"Keyword\" and click Apply. In the new Google Ads experience, turn on the “Keyword” column by clicking the column icon Columns, then clicking Attributes. Tick the box beside “Keyword,” then click Apply."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning approach\n",
    "similar to learning to rank algorithm. \n",
    "Training data is used by a learning algorithm to produce a ranking model which computes the relevance of documents for actual queries.(In this case it would compute the relevance of search keywords to search intentions.\n",
    "\n",
    "To populate the training data we couuld as per phase 1 compute the relevance of search responses to search intention keywords to provide the labels for training/test search queries. the overall implementation could be that when we enter a search query the search engine will predict our search intention/goal before submitting the query. this can also be used to further train the algorithm if we give possibility to corret the prediction.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6 PyEnv",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
